
seed: 42
sampling_random_state: 42
# num_samplings: the number of samplings to train/validate the model
# in a low datasetting. Empty represent all data
num_samplings_train: 4000
num_samplings_val: 
# Available model_name to choose from: bert-base-uncased, roberta-base, microsoft/deberta-base
model_name: roberta-base
# tuning method can be chosen among {0, 1, 2},
# where 0 stands for fine tuning
# 1 stands for prompt tuning, and 
# 2 stands for prefix tuning 
tuning_method: 1
model_save_name: all_roberta_li1.pth
learning_rate: 2.0e-2
classifier: li # please choose from {li, dml}, li stands for linear layer, dml stands for deep metric learning
num_virtual_tokens : 7
batch_size: 32
epoch: 50
num_hidden_states: 768